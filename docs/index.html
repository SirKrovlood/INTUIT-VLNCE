<html>

<head>
    <title>Language-Aligned Waypoint (LAW) Supervision for VLN-CE</title>
    <link rel="stylesheet" href="css/index.css" />
</head>

<body>
    <div class="container">
        <div class="header" id="header">
            <h1>Language-Aligned Waypoint (LAW) Supervision for Vision-and-Language Navigation in Continuous
                Environments</h1>
            <ul>
                <li><a href="#">Sonia Raychaudhuri<sup>1</sup></a></li>
                <li><a href="https://saimwani.github.io/">Saim Wani<sup>2</sup></a></li>
                <li><a href="https://shivanshpatel35.github.io/">Shivansh Patel<sup>2</sup></a></li>
                <li><a href="https://unnat.github.io/">Unnat Jain<sup>3</sup></a></li>
                <li><a href="https://angelxuanchang.github.io/">Angel X. Chang<sup>1</sup></a></li>
            </ul>
            <span><sup>1</sup>Simon Fraser University, &nbsp; <sup>2</sup>IIT Kanpur, &nbsp; <sup>3</sup>UIUC </span>
            <span>EMNLP 2021</span>
        </div>
        <div class="link-bar">

        </div>

        <div class="section abstract">
            <h2>Abstract</h2>
            <p class="text-justify">
                In the Vision-and-Language Navigation (VLN) task an embodied agent navigates a 3D environment, following
                natural language instructions. A challenge in this task is how to handle ‘off the path’ scenarios where
                an agent veers from a reference path. Prior work supervises the agent with actions based on the shortest
                path from the agent’s location to the goal, but such goal-oriented supervision is often not in alignment
                with the instruction. Furthermore, the evaluation metrics employed by prior work do not measure how much
                of a language instruction the agent is able to follow. In this work, we propose a simple and effective
                language-aligned supervision scheme, and a new metric that measures the number of sub-instructions the
                agent has completed during navigation.
            </p>

        </div>
        <div class="link-bar">
            [<a href="https://github.com/3dlg-hcvc/LAW-VLNCE">GitHub</a>]
            [<a href="#">Paper</a>]
        </div>
        <div class="section video">
            <h2>Summary Video</h2>
            <iframe width="560" height="315" src="#" title="YouTube video player" frameborder="0"
                allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                allowfullscreen></iframe>
        </div>


        <div class="section qualitative-results">
            <h2>Qualitative Results</h2>
            &nbsp;
        </div>

        <div class="section results">
            <h2>Quantitative Results</h2>
            <div class="results-table">
                &nbsp;
            </div>
        </div>

        <div class="section qualitative-results">
            <h2>Pretrained models</h2>
            <p>&nbsp;</p>
        </div>

        <div class="section">
            <h2>Citation</h2>
            <p>If you find our work useful, please cite our paper below.<br></p>
            <div>
                &nbsp;
            </div>
        </div>

    </div>
    <br />

</body>

</html>