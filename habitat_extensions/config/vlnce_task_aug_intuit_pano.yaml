# Same as vlnce_task.yaml but with a dataset split that
# contains both the training and EnvDrop episodes.

ENVIRONMENT:
  MAX_EPISODE_STEPS: 7500
SIMULATOR:
  TYPE: "Sim-dual"
  AGENTS: [ "AGENT_0", "AGENT_1" ]
  AGENT_1:
    SENSORS: None
    ANGULAR_ACCELERATION: 12.56
    ANGULAR_FRICTION: 1.0
    COEFFICIENT_OF_RESTITUTION: 0.0
    HEIGHT: 1.5
    IS_SET_START_STATE: True
    LINEAR_ACCELERATION: 20.0
    LINEAR_FRICTION: 0.5
    MASS: 32.0
    RADIUS: 0.1
    START_POSITION: [ 0.0, 0.0, 0.0 ]
    START_ROTATION: [ -0.0, 0.49999999999999994, -0.0, -0.8660254037844387 ]
  AGENT_0:
    SENSORS: [RGB_SENSOR, DEPTH_SENSOR]
  FORWARD_STEP_SIZE: 0.25
  TURN_ANGLE: 15
  HABITAT_SIM_V0:
    GPU_DEVICE_ID: 0
    ALLOW_SLIDING: True
  RGB_SENSOR:
    WIDTH: 224
    HEIGHT: 224
    HFOV: 90
    TYPE: HabitatSimRGBSensor
  DEPTH_SENSOR:
    WIDTH: 256  # pretrained DDPPO resnet needs 256x256
    HEIGHT: 256
TASK:
  #TYPE: Nav-dual
  TYPE: VLN-v0
  SUCCESS_DISTANCE: 3.0
  SENSORS: [
    INSTRUCTION_SENSOR,
    VLN_ORACLE_GEODESIC_ACTION_SENSOR,
    VLN_ORACLE_PROGRESS_SENSOR
  ]
  INSTRUCTION_SENSOR_UUID: instruction
  POSSIBLE_ACTIONS: [STOP, MOVE_FORWARD, TURN_LEFT, TURN_RIGHT]
  MEASUREMENTS: [
    DISTANCE_TO_GOAL,
    SUCCESS,
    SPL,
    NDTW,
    SDTW,
    PATH_LENGTH,
    ORACLE_SUCCESS,
    STEPS_TAKEN,
    WAYPOINT_ACCURACY
  ]
  SUCCESS:
    SUCCESS_DISTANCE: 3.0
  SPL:
    SUCCESS_DISTANCE: 3.0
  NDTW:
    SUCCESS_DISTANCE: 3.0
    GT_PATH: data/datasets/R2R_VLNCE_v1-3_preprocessed/local_train/local_train_gt.json.gz
  SDTW:
    SUCCESS_DISTANCE: 3.0
    GT_PATH: data/datasets/R2R_VLNCE_v1-3_preprocessed/local_train/local_train_gt.json.gz
  ORACLE_SUCCESS:
    SUCCESS_DISTANCE: 3.0
DATASET:
  TYPE: VLN-CE-v1
  SPLIT: joint_train_envdrop
  DATA_PATH: data/datasets/R2R_VLNCE_v1-3_preprocessed/local_train/local_train.json.gz
  SCENES_DIR: data/scene_datasets/
